{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7kWJaDPPIm+9OH3S3oSPF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ra1111/Text-Analytics/blob/main/Text_analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bZH8uPHFONe",
        "outputId": "f9db3440-ae5e-422e-d7f2-e4fe1ca6b162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text preprocess involv remov special charact stopword\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "text = \"Text preprocessing involves removing special characters and stopwords.\"\n",
        "preprocessed_text = preprocess_text(text)\n",
        "print(preprocessed_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "text = \"Text tokenization breaks down sentences into words for analysis.\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G9Tt-3TFPDh",
        "outputId": "8088d050-2236-4b73-9142-6a04e6724ff1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Text', 'tokenization', 'breaks', 'down', 'sentences', 'into', 'words', 'for', 'analysis', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "text = \"Part-of-speech tagging categorizes words by their grammatical roles.\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(pos_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfBXBCTDk7iZ",
        "outputId": "693d1eca-c740-49d1-979a-13819bb4609c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Part-of-speech', 'JJ'), ('tagging', 'NN'), ('categorizes', 'NNS'), ('words', 'NNS'), ('by', 'IN'), ('their', 'PRP$'), ('grammatical', 'JJ'), ('roles', 'NNS'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "text = \"Apple Inc. was founded by Steve Jobs in Cupertino, California in 1976.\"\n",
        "words = nltk.word_tokenize(text)\n",
        "entities = nltk.ne_chunk(nltk.pos_tag(words))\n",
        "print(entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt7x2iCBk9gx",
        "outputId": "f34408e1-e08f-4680-f82f-cf9d6a8518ef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON Apple/NNP)\n",
            "  (ORGANIZATION Inc./NNP)\n",
            "  was/VBD\n",
            "  founded/VBN\n",
            "  by/IN\n",
            "  (PERSON Steve/NNP Jobs/NNP)\n",
            "  in/IN\n",
            "  (GPE Cupertino/NNP)\n",
            "  ,/,\n",
            "  (GPE California/NNP)\n",
            "  in/IN\n",
            "  1976/CD\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kN-ZGO1k_oj",
        "outputId": "244c8b96-1a33-48fe-f97c-34be5b344122"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text = \"I love this product! It's amazing.\"\n",
        "analysis = TextBlob(text)\n",
        "sentiment = analysis.sentiment.polarity\n",
        "\n",
        "if sentiment > 0:\n",
        "    print(\"Positive sentiment\")\n",
        "elif sentiment < 0:\n",
        "    print(\"Negative sentiment\")\n",
        "else:\n",
        "    print(\"Neutral sentiment\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3ir1Iy0mhBm",
        "outputId": "d81ef9e8-28db-47c9-8f11-b8c45c8e2751"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "documents = [\"Topic modeling is an important technique.\",\n",
        "             \"It helps in uncovering hidden themes.\",\n",
        "             \"These themes are present in a collection of texts.\"]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=2, random_state=0)\n",
        "lda.fit(X)\n",
        "\n",
        "# Get the most representative keywords for each topic\n",
        "def get_top_words_per_topic(model, feature_names, n_top_words):\n",
        "    top_words = []\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        top_words_idx = topic.argsort()[:-n_top_words - 1:-1]\n",
        "        top_words.append([feature_names[i] for i in top_words_idx])\n",
        "    return top_words\n",
        "\n",
        "n_top_words = 3\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "top_words = get_top_words_per_topic(lda, feature_names, n_top_words)\n",
        "\n",
        "for i, words in enumerate(top_words):\n",
        "    print(f\"Topic {i + 1}: {', '.join(words)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JO-z6wIDbbf",
        "outputId": "58960d1c-8b3f-4b76-eabe-3745af3e0cfa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: themes, in, are\n",
            "Topic 2: technique, modeling, is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JFh_ZGksDlaJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}